{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"00-Semantics-and-Word-Vectors.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOYx6hslZZV45CXBjeWqcPQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Semantics and Word Vectors"],"metadata":{"id":"FwjRYO6HRWa7"}},{"cell_type":"markdown","source":["# Installing Larger spaCy Models"],"metadata":{"id":"fA5vOdsRRsDz"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"cqY2UntRQ3bE","executionInfo":{"status":"ok","timestamp":1641873639402,"user_tz":-330,"elapsed":101460,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b22eeb9a-a662-4d0c-e5e6-d5cfe5dd6957"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting en_core_web_md==2.2.5\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4 MB)\n","\u001b[K     |████████████████████████████████| 96.4 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.6)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.6)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.4.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.6)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.62.3)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.19.5)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.10.0.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_md')\n","Collecting en_core_web_lg==2.2.5\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9 MB)\n","\u001b[K     |████████████████████████████████| 827.9 MB 1.1 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.2)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.62.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (57.4.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.6)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.6)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.8.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_lg')\n"]}],"source":["!python -m spacy download en_core_web_md\n","!python -m spacy download en_core_web_lg"]},{"cell_type":"markdown","source":["<font color=lightgreen>Of course, we have a third option, and that is to train our own vectors from a large corpus of documents. Unfortunately this would take a prohibitively large amount of time and processing power.</font> "],"metadata":{"id":"faYbJi90SKAq"}},{"cell_type":"markdown","source":["# Word Vectors\n","Word vectors - also called *word embeddings* - are mathematical descriptions of individual words such that words that appear frequently together in the language will have similar values. In this way we can mathematically derive *context*. As mentioned above, the word vector for \"lion\" will be closer in value to \"cat\" than to \"dandelion\"."],"metadata":{"id":"QzfT2SsASMc5"}},{"cell_type":"markdown","source":["## Vector values\n","So what does a word vector look like? Since spaCy employs 300 dimensions, word vectors are stored as 300-item arrays.\n","\n","Note that we would see the same set of values with **en_core_web_md** and **en_core_web_lg**, as both were trained using the [word2vec](https://en.wikipedia.org/wiki/Word2vec) family of algorithms."],"metadata":{"id":"G8fHw685SSVS"}},{"cell_type":"code","source":["# Import spaCy and load the language library\n","import spacy\n","nlp = spacy.load('en_core_web_lg')"],"metadata":{"id":"5WPN32T9Rw-J","executionInfo":{"status":"ok","timestamp":1641873649865,"user_tz":-330,"elapsed":10472,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["nlp(u'lion').vector"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OcQypsB4Sh-J","executionInfo":{"status":"ok","timestamp":1641873650648,"user_tz":-330,"elapsed":794,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"598327e6-960d-42a3-bdb3-d37d2f99a7ab"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1.8963e-01, -4.0309e-01,  3.5350e-01, -4.7907e-01, -4.3311e-01,\n","        2.3857e-01,  2.6962e-01,  6.4332e-02,  3.0767e-01,  1.3712e+00,\n","       -3.7582e-01, -2.2713e-01, -3.5657e-01, -2.5355e-01,  1.7543e-02,\n","        3.3962e-01,  7.4723e-02,  5.1226e-01, -3.9759e-01,  5.1333e-03,\n","       -3.0929e-01,  4.8911e-02, -1.8610e-01, -4.1702e-01, -8.1639e-01,\n","       -1.6908e-01, -2.6246e-01, -1.5983e-02,  1.2479e-01, -3.7276e-02,\n","       -5.7125e-01, -1.6296e-01,  1.2376e-01, -5.5464e-02,  1.3244e-01,\n","        2.7519e-02,  1.2592e-01, -3.2722e-01, -4.9165e-01, -3.5559e-01,\n","       -3.0630e-01,  6.1185e-02, -1.6932e-01, -6.2405e-02,  6.5763e-01,\n","       -2.7925e-01, -3.0450e-03, -2.2400e-02, -2.8015e-01, -2.1975e-01,\n","       -4.3188e-01,  3.9864e-02, -2.2102e-01, -4.2693e-02,  5.2748e-02,\n","        2.8726e-01,  1.2315e-01, -2.8662e-02,  7.8294e-02,  4.6754e-01,\n","       -2.4589e-01, -1.1064e-01,  7.2250e-02, -9.4980e-02, -2.7548e-01,\n","       -5.4097e-01,  1.2823e-01, -8.2408e-02,  3.1035e-01, -6.3394e-02,\n","       -7.3755e-01, -5.4992e-01,  9.9999e-02, -2.0758e-01, -3.9674e-02,\n","        2.0664e-01, -9.7557e-02, -3.7092e-01,  2.7901e-01, -6.2218e-01,\n","       -1.0280e-01,  2.3271e-01,  4.3838e-01,  3.2445e-02, -2.9866e-01,\n","       -7.3611e-02,  7.1594e-01,  1.4241e-01,  2.7770e-01, -3.9892e-01,\n","        3.6656e-02,  1.5759e-01,  8.2014e-02, -5.7343e-01,  3.5457e-01,\n","        2.2491e-01, -6.2699e-01, -8.8106e-02,  2.4361e-01,  3.8533e-01,\n","       -1.4083e-01,  1.7691e-01,  7.0897e-02,  1.7951e-01, -4.5907e-01,\n","       -8.2120e-01, -2.6631e-02,  6.2549e-02,  4.2415e-01, -8.9630e-02,\n","       -2.4654e-01,  1.4156e-01,  4.0187e-01, -4.1232e-01,  8.4516e-02,\n","       -1.0626e-01,  7.3145e-01,  1.9217e-01,  1.4240e-01,  2.8511e-01,\n","       -2.9454e-01, -2.1948e-01,  9.0460e-01, -1.9098e-01, -1.0340e+00,\n","       -1.5754e-01, -1.1964e-01,  4.9888e-01, -1.0624e+00, -3.2820e-01,\n","       -1.1232e-02, -7.9482e-01,  3.7275e-01, -6.8710e-03, -2.5772e-01,\n","       -4.7005e-01, -4.1387e-01, -6.4089e-02, -2.8033e-01, -4.0778e-02,\n","       -2.4866e+00,  6.2494e-03, -1.0210e-02,  1.2752e-01,  3.4965e-01,\n","       -1.2571e-01,  3.1570e-01,  4.1926e-01,  2.0056e-01, -5.5984e-01,\n","       -2.2801e-01,  1.2012e-01, -2.0518e-03, -8.9764e-02, -8.0373e-02,\n","        1.1969e-02, -2.6978e-01,  3.4829e-01,  7.3664e-03, -1.1137e-01,\n","        6.3410e-01,  3.8449e-01, -6.2248e-01,  4.1145e-02,  2.5922e-01,\n","        6.5811e-01, -4.9548e-01, -1.3030e-01, -3.8279e-01,  1.1156e-01,\n","       -4.3085e-01,  3.4473e-01,  2.7109e-02, -2.5108e-01, -2.8011e-01,\n","        2.1662e-01,  3.2660e-01,  5.5895e-02,  7.6077e-02, -5.2480e-02,\n","        4.5928e-02, -2.5266e-01,  5.2845e-01, -1.3145e-01, -1.2453e-01,\n","        4.0556e-01,  3.1877e-01,  2.4415e-02, -2.2620e-01, -6.1960e-01,\n","       -4.0886e-01, -3.5534e-02, -5.5123e-03,  2.3438e-01,  8.7854e-01,\n","       -2.5161e-01,  4.0600e-01, -4.4284e-01,  3.4934e-01, -5.6429e-01,\n","       -2.3676e-01,  6.2199e-01, -2.8175e-01,  4.2024e-01,  1.0043e-01,\n","       -1.4720e-01,  4.9593e-01, -3.5850e-01, -1.3998e-01, -2.7494e-01,\n","        2.3827e-01,  5.7268e-01,  7.9025e-02,  1.7872e-02, -2.1829e-01,\n","        5.5050e-02, -5.4200e-01,  1.6788e-01,  3.9065e-01,  3.0209e-01,\n","        2.3040e-01, -3.9351e-02, -2.1078e-01, -2.7224e-01,  1.6907e-01,\n","        5.4819e-01,  9.4888e-02,  7.9798e-01, -6.6158e-02,  1.9844e-01,\n","        2.0307e-01,  4.4808e-02, -1.0240e-01, -6.9909e-02, -3.6756e-02,\n","        9.5159e-02, -2.7830e-01, -1.0597e-01, -1.6276e-01, -1.8211e-01,\n","       -3.1897e-01, -2.1633e-01,  1.4994e-01, -7.2057e-02,  2.2264e-01,\n","       -4.5551e-01,  3.0341e-01,  1.8431e-01,  2.1681e-01, -3.1940e-01,\n","        2.6426e-01,  5.8106e-01,  5.4635e-02,  6.3238e-01,  4.3169e-01,\n","        9.0343e-02,  1.9494e-01,  3.5483e-01, -2.0706e-02, -7.3117e-01,\n","        1.2941e-01,  1.7418e-01, -1.5065e-01,  5.3355e-02,  4.4794e-02,\n","       -1.6600e-01,  2.2007e-01, -5.3970e-01, -2.4968e-01, -2.6464e-01,\n","       -5.5515e-01,  5.8242e-01,  2.2295e-01,  2.4433e-01,  4.5275e-01,\n","        3.4693e-01,  1.2255e-01, -3.9059e-02, -3.2749e-01, -2.7891e-01,\n","        1.3766e-01,  3.8392e-01,  1.0543e-03, -1.0242e-02,  4.9205e-01,\n","       -1.7922e-01,  4.1215e-02,  1.3547e-01, -2.0598e-01, -2.3194e-01,\n","       -7.7701e-01, -3.8237e-01, -7.6383e-01,  1.9418e-01, -1.5441e-01,\n","        8.9740e-01,  3.0626e-01,  4.0376e-01,  2.1738e-01, -3.8050e-01],\n","      dtype=float32)"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["What's interesting is that Doc and Span objects themselves have vectors, derived from the averages of individual token vectors. <br>This makes it possible to compare similarities between whole documents."],"metadata":{"id":"912UK7yMTcSm"}},{"cell_type":"code","source":["doc = nlp(u'The quick brown fox jumped over the lazy dogs.')\n","\n","doc.vector"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"II40TVUPSjlq","executionInfo":{"status":"ok","timestamp":1641873650648,"user_tz":-330,"elapsed":39,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"b3688a70-829d-49db-bb35-db4c5c04939f"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-1.96635887e-01, -2.32740352e-03, -5.36607020e-02, -6.10564947e-02,\n","       -4.08843048e-02,  1.45266443e-01, -1.08268000e-01, -6.27789786e-03,\n","        1.48455709e-01,  1.90697408e+00, -2.57692993e-01, -1.95818534e-03,\n","       -1.16141019e-02, -1.62858292e-01, -1.62938282e-01,  1.18210977e-02,\n","        5.12646027e-02,  1.00078702e+00, -2.01447997e-02, -2.54611671e-01,\n","       -1.28316596e-01, -1.97198763e-02, -2.89733019e-02, -1.94347113e-01,\n","        1.26644447e-01, -8.69869068e-02, -2.20812604e-01, -1.58452198e-01,\n","        9.86308008e-02, -1.79210991e-01, -1.55290633e-01,  1.95643142e-01,\n","        2.66436003e-02, -1.64984968e-02,  1.18824698e-01, -1.17830629e-03,\n","        4.99809943e-02, -4.23077159e-02, -3.86111848e-02, -7.47400150e-03,\n","        1.23448208e-01,  9.60620027e-03, -3.32463719e-02, -1.77848607e-01,\n","        1.19390726e-01,  1.87545009e-02, -1.84173390e-01,  6.91781715e-02,\n","        1.28520593e-01,  1.48827005e-02, -1.78013414e-01,  1.10003807e-01,\n","       -3.35464999e-02, -1.52476998e-02, -9.41195935e-02,  1.58633105e-02,\n","       -1.29811959e-02,  1.40140295e-01, -1.47720069e-01, -3.81718054e-02,\n","        4.66808230e-02,  3.31423879e-02,  7.97965974e-02,  1.60014004e-01,\n","        8.90410226e-03, -1.01237908e-01,  7.39663988e-02,  2.47380026e-02,\n","        4.26153988e-02,  9.66729969e-02,  2.87616011e-02,  7.22841993e-02,\n","        1.76565602e-01,  7.55538046e-02,  1.10501610e-01, -1.02358103e-01,\n","       -5.43345436e-02, -4.12176028e-02,  3.98623049e-02, -2.98339734e-03,\n","       -5.32988012e-02,  1.90624595e-01, -6.42587021e-02, -1.76225007e-02,\n","        3.94165330e-02, -1.14773512e-01,  4.25241649e-01,  2.07243040e-01,\n","        2.60730416e-01,  1.31226778e-01, -8.00508037e-02,  6.88939020e-02,\n","        7.05293044e-02, -1.10744104e-01,  4.14580032e-02,  5.13269613e-03,\n","       -1.29179001e-01, -5.84542975e-02,  9.13560018e-02, -1.75975591e-01,\n","        9.52741057e-02,  1.37699964e-02, -1.30865201e-01, -4.76420000e-02,\n","        1.61670998e-01, -6.76959991e-01,  2.68619388e-01, -7.94106945e-02,\n","        8.56394917e-02, -5.94138019e-02,  7.44821057e-02, -1.67490095e-01,\n","        1.97447598e-01, -2.71580786e-01,  1.51915969e-02,  1.12019002e-01,\n","       -4.32585999e-02, -1.03554968e-02,  6.33272156e-02,  5.20200143e-03,\n","        4.94491048e-02, -1.07016601e-01, -6.45387918e-02, -1.76269561e-01,\n","       -1.98135704e-01,  4.17800918e-02,  1.23686995e-02, -1.13280594e-01,\n","       -4.03523073e-02, -4.21132054e-03, -9.65667963e-02, -7.12300017e-02,\n","       -2.19088510e-01,  6.41715974e-02,  1.11634992e-01, -7.12868944e-02,\n","       -8.27060193e-02,  1.53889004e-02,  6.84699565e-02, -5.50561920e-02,\n","       -1.84788990e+00, -4.75010052e-02,  1.31487206e-01,  1.03359401e-01,\n","        1.80857688e-01, -8.03041980e-02,  2.27739997e-02,  5.56868985e-02,\n","        9.20986086e-02,  6.22248054e-02,  4.86670025e-02, -4.06427011e-02,\n","        3.83703932e-02, -4.05869968e-02, -2.26339817e-01,  3.69174965e-02,\n","       -1.30066186e-01,  1.27621710e-01,  2.76701003e-02, -1.39992401e-01,\n","       -3.75526994e-02, -8.11104029e-02, -1.78196102e-01, -1.21652998e-01,\n","       -5.88919744e-02, -1.06128812e-01, -4.72390745e-03, -1.14130601e-01,\n","       -7.60087445e-02, -9.48704034e-02,  1.68780401e-01,  3.82669941e-02,\n","       -1.68303996e-01, -1.30991384e-01, -2.46409744e-01,  1.42855030e-02,\n","        1.23633012e-01,  7.95699935e-03, -3.22283022e-02,  3.75844017e-02,\n","       -4.48104031e-02, -2.00578898e-01, -2.86081016e-01, -1.83181003e-01,\n","       -5.46899159e-04,  6.52990937e-02,  2.34263036e-02, -7.60660022e-02,\n","        1.13897599e-01, -7.05380812e-02,  1.30277812e-01,  2.83973999e-02,\n","        1.73887815e-02, -1.71358977e-02,  1.78455990e-02,  1.86773703e-01,\n","        1.83613986e-01, -4.05438878e-02,  1.28929759e-03, -3.71900201e-03,\n","       -1.97373003e-01,  4.78463694e-02, -2.21408010e-01,  2.68826094e-02,\n","        2.40951017e-01,  7.42616802e-02,  7.53984973e-02, -7.67349079e-02,\n","       -5.37766796e-03, -8.06540065e-03,  1.88790001e-02,  8.31135064e-02,\n","       -5.20760007e-02,  1.29393607e-01,  4.09864075e-02,  7.31946975e-02,\n","       -1.64099425e-01,  1.17529690e-01, -6.96440935e-02,  1.91028208e-01,\n","        1.01721905e-01,  6.34808987e-02, -8.29815865e-02, -6.95784390e-03,\n","       -1.69757873e-01, -2.02478573e-01,  3.65395918e-02,  1.32345587e-01,\n","        3.53013016e-02,  2.27603033e-01, -1.52753398e-01,  7.80210178e-03,\n","        2.06879750e-02, -8.63540452e-03,  9.85722095e-02, -2.91380938e-02,\n","       -1.42988954e-02, -9.39018354e-02,  1.43968105e-01,  7.82396942e-02,\n","       -1.93540990e-01, -9.36544985e-02, -8.23533013e-02,  4.40272018e-02,\n","       -2.22195080e-03, -1.29856914e-01, -1.53841600e-01, -1.55329984e-02,\n","       -2.55266696e-01,  1.14425398e-01, -1.03161987e-02, -4.66439016e-02,\n","       -5.69390282e-02,  7.72780031e-02,  1.28908500e-01,  1.61679000e-01,\n","        1.50837511e-01,  6.18334934e-02, -9.06937942e-02, -3.52137014e-02,\n","        1.35956988e-01,  7.52059072e-02,  5.73905036e-02, -1.65402606e-01,\n","        1.68419987e-01, -1.83722824e-01,  5.91069926e-03, -1.25354990e-01,\n","        3.95771042e-02,  5.67352995e-02, -5.63519308e-03,  1.53597593e-01,\n","       -6.84822723e-02, -1.40976995e-01, -3.62732522e-02, -2.61475928e-02,\n","        2.50091963e-02,  1.18994810e-01, -2.66857035e-02,  7.50442073e-02,\n","        2.04583794e-01,  4.37736101e-02, -8.17096978e-02,  6.80228025e-02,\n","        5.50465994e-02, -2.39979066e-02,  7.68290013e-02, -5.76773956e-02,\n","        8.30340981e-02,  3.63199934e-02, -1.65820405e-01,  2.55408939e-02,\n","       -5.30679002e-02, -1.35961995e-01, -1.03501797e-01,  1.36406809e-01,\n","        9.66293067e-02,  7.33902007e-02, -1.83055893e-01, -2.73141060e-02],\n","      dtype=float32)"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["## Identifying similar vectors\n","The best way to expose vector relationships is through the `.similarity()` method of Doc tokens."],"metadata":{"id":"M-ES4cdMTi-W"}},{"cell_type":"code","source":["from prettytable import PrettyTable\n","\n","def similarity_matrix(tokens):\n","    # Iterate through token combinations:\n","    t = PrettyTable([\" \", *tokens])\n","\n","    for token1 in tokens:\n","        temp_list = [\"**\" + token1.text + \"**\"]\n","        for token2 in tokens:\n","            temp_list += [token1.similarity(token2)]\n","        t.add_row(temp_list)\n","\n","    print(t)"],"metadata":{"id":"uq3BYhsuWz1R","executionInfo":{"status":"ok","timestamp":1641873650649,"user_tz":-330,"elapsed":37,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Create a three-token Doc object:\n","tokens = nlp(u'lion cat pet')\n","\n","similarity_matrix(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x7CEaKvETiNe","executionInfo":{"status":"ok","timestamp":1641873650650,"user_tz":-330,"elapsed":37,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"a53ab08c-6b9f-430f-d82a-8de87d8a4f37"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+-----------+------------+\n","|          |    lion    |    cat    |    pet     |\n","+----------+------------+-----------+------------+\n","| **lion** |    1.0     | 0.5265438 | 0.39923766 |\n","| **cat**  | 0.5265438  |    1.0    | 0.7505457  |\n","| **pet**  | 0.39923766 | 0.7505457 |    1.0     |\n","+----------+------------+-----------+------------+\n"]}]},{"cell_type":"markdown","source":["<font color=lightgreen>Note that order doesn't matter. `token1.similarity(token2)` has the same value as `token2.similarity(token1)`.</font>\n","#### To view this as a table:"],"metadata":{"id":"iJC5AyxQTyBg"}},{"cell_type":"markdown","source":["As expected, we see the strongest similarity between \"cat\" and \"pet\", the weakest between \"lion\" and \"pet\", and some similarity between \"lion\" and \"cat\". A word will have a perfect (1.0) similarity with itself.\n","\n","If you're curious, the similarity between \"lion\" and \"dandelion\" is very small:"],"metadata":{"id":"1lXESVv7VZ98"}},{"cell_type":"code","source":["nlp(u'lion').similarity(nlp(u'dandelion'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8GhBlW1GUgzd","executionInfo":{"status":"ok","timestamp":1641873650650,"user_tz":-330,"elapsed":32,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"775be6e1-2f09-4cb0-994d-da03fffb6f63"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.19291049251681294"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["### Opposites are not necessarily different\n","Words that have opposite meaning, but that often appear in the same *context* may have similar vectors."],"metadata":{"id":"8NiiNTo9Vn1B"}},{"cell_type":"code","source":["# Create a three-token Doc object:\n","tokens = nlp(u'like love hate')\n","\n","similarity_matrix(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X_TsaQj7Vhft","executionInfo":{"status":"ok","timestamp":1641873650651,"user_tz":-330,"elapsed":29,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"3bc28b1a-1b08-4303-9973-9b6cb4cdcbe0"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+------------+------------+\n","|          |    like    |    love    |    hate    |\n","+----------+------------+------------+------------+\n","| **like** |    1.0     |  0.657904  | 0.65746516 |\n","| **love** |  0.657904  |    1.0     | 0.63930994 |\n","| **hate** | 0.65746516 | 0.63930994 |    1.0     |\n","+----------+------------+------------+------------+\n"]}]},{"cell_type":"code","source":["nlp.vocab.vectors.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UuMzBPSAX2B4","executionInfo":{"status":"ok","timestamp":1641873650652,"user_tz":-330,"elapsed":27,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"cfb992a0-5e7b-463c-a3a0-c07abdb4dff5"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(684831, 300)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## Vector norms\n","It's sometimes helpful to aggregate 300 dimensions into a [Euclidian (L2) norm](https://en.wikipedia.org/wiki/Norm_%28mathematics%29#Euclidean_norm), computed as the square root of the sum-of-squared-vectors. This is accessible as the `.vector_norm` token attribute. Other helpful attributes include `.has_vector` and `.is_oov` or *out of vocabulary*.\n","\n","For example, our 685k vector library may not have the word \"[nargle](https://en.wikibooks.org/wiki/Muggles%27_Guide_to_Harry_Potter/Magic/Nargle)\". To test this:"],"metadata":{"id":"cWRJw1uIXQO5"}},{"cell_type":"code","source":["tokens = nlp(u'dog cat nargle')\n","\n","t = PrettyTable([\"Text\", \"Has Vector\", \"Euclidian (L2) norm\", \"Out of Vocabulary\"])\n","\n","for token in tokens:\n","    t.add_row([token.text, token.has_vector, token.vector_norm, token.is_oov])\n","\n","print(t)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UbChecI1VtfA","executionInfo":{"status":"ok","timestamp":1641873650652,"user_tz":-330,"elapsed":24,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"a89a4ebb-beb3-489e-bb02-a583833f7ea5"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------+------------+---------------------+-------------------+\n","|  Text  | Has Vector | Euclidian (L2) norm | Out of Vocabulary |\n","+--------+------------+---------------------+-------------------+\n","|  dog   |    True    |      7.0336733      |       False       |\n","|  cat   |    True    |      6.6808186      |       False       |\n","| nargle |   False    |         0.0         |        True       |\n","+--------+------------+---------------------+-------------------+\n"]}]},{"cell_type":"markdown","source":["Indeed we see that \"nargle\" does not have a vector, so the vector_norm value is zero, and it identifies as *out of vocabulary*."],"metadata":{"id":"b-U3NbHNYNjZ"}},{"cell_type":"markdown","source":["## Vector arithmetic\n","Believe it or not, we can actually calculate new vectors by adding & subtracting related vectors. A famous example suggests\n","<pre>\"king\" - \"man\" + \"woman\" = \"queen\"</pre>\n","Let's try it out!"],"metadata":{"id":"jEfdidXrYQk3"}},{"cell_type":"code","source":["from scipy import spatial\n","\n","cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n","\n","king = nlp.vocab['king'].vector\n","man = nlp.vocab['man'].vector\n","woman = nlp.vocab['woman'].vector\n","\n","# Now we find the closest vector in the vocabulary to the result of \"man\" - \"woman\" + \"queen\"\n","new_vector = king - man + woman\n","computed_similarities = []\n","\n","for word in nlp.vocab:\n","    # Ignore words without vectors and mixed-case words:\n","    if word.has_vector:\n","        if word.is_lower:\n","            if word.is_alpha:\n","                similarity = cosine_similarity(new_vector, word.vector)\n","                computed_similarities.append((word, similarity))\n","\n","computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n","\n","print([w[0].text for w in computed_similarities[:10]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l2KnfLPeXdwS","executionInfo":{"status":"ok","timestamp":1641873668913,"user_tz":-330,"elapsed":18280,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"56a10e89-2bbf-478a-8689-4ee90945f4fc"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["['king', 'queen', 'prince', 'kings', 'princess', 'royal', 'throne', 'queens', 'monarch', 'kingdom']\n"]}]},{"cell_type":"markdown","source":["So in this case, \"king\" was still closer than \"queen\" to our calculated vector, although \"queen\" did show up!"],"metadata":{"id":"bxHLj4nLZrl_"}}]}