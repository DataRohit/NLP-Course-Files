{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01-Feature-Extraction-from-Text.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyODJAtUid2Z2SKnOVbO5Uyu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Mounting Google Drive"],"metadata":{"id":"QZocIhhIo1ww"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/Drive\")\n","\n","base_path = \"/content/Drive/MyDrive/NLP-Course/03-Text-Classification/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyalVwr6o4gB","executionInfo":{"status":"ok","timestamp":1641878098379,"user_tz":-330,"elapsed":4157,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"92d37f96-edb0-4fa0-c81a-b65d92895145"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/Drive; to attempt to forcibly remount, call drive.mount(\"/content/Drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Building a Natural Language Processor From Scratch\n","In this section we'll use basic Python to build a rudimentary NLP system. We'll build a *corpus of documents* (two small text files), create a *vocabulary* from all the words in both documents, and then demonstrate a *Bag of Words* technique to extract features from each document.<br>"],"metadata":{"id":"oWTmFdZvowug"}},{"cell_type":"markdown","source":["## Start with some documents:\n","For simplicity we won't use any punctuation."],"metadata":{"id":"YVhXBL2MpN1o"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"WjSZLH3PoQ5k","executionInfo":{"status":"ok","timestamp":1641878098383,"user_tz":-330,"elapsed":40,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}}},"outputs":[],"source":["f1 = open(base_path + \"test_1.txt\", \"w\")\n","f1.write(\"This is a story about cats\\nour feline pets\\nCats are furry animals\")\n","f1.close()"]},{"cell_type":"code","source":["f2 = open(base_path + \"test_2.txt\", \"w\")\n","f2.write(\"This story is about surfing\\nCatching waves is fun\\nSurfing is a popular water sport\")\n","f2.close()"],"metadata":{"id":"3pUU-_2ApfY_","executionInfo":{"status":"ok","timestamp":1641878098384,"user_tz":-330,"elapsed":40,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Build a vocabulary\n","The goal here is to build a numerical array from all the words that appear in every document. Later we'll create instances (vectors) for each individual document."],"metadata":{"id":"ZRtSERsXpoJg"}},{"cell_type":"code","source":["vocab = {}\n","i = 1\n","\n","f1 = open(base_path + \"test_1.txt\", \"r\")\n","x = f1.read().lower().split()\n","f1.close()\n","\n","for word in x:\n","    if word in vocab:\n","        continue\n","    else:\n","        vocab[word]=i\n","        i+=1\n","\n","print(vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4KSb8nuUpmSH","executionInfo":{"status":"ok","timestamp":1641878098385,"user_tz":-330,"elapsed":40,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"d95f6fb7-f115-4135-fcd8-cf5fcca14b0d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["{'this': 1, 'is': 2, 'a': 3, 'story': 4, 'about': 5, 'cats': 6, 'our': 7, 'feline': 8, 'pets': 9, 'are': 10, 'furry': 11, 'animals': 12}\n"]}]},{"cell_type":"code","source":["f2 = open(base_path + \"test_2.txt\", \"r\")\n","x = f2.read().lower().split()\n","f2.close()\n","\n","for word in x:\n","    if word in vocab:\n","        continue\n","    else:\n","        vocab[word]=i\n","        i+=1\n","\n","print(vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sCLFrD4rqNUI","executionInfo":{"status":"ok","timestamp":1641878098386,"user_tz":-330,"elapsed":38,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"614f0d01-aff8-426f-cb1b-85ec9bea5dd9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["{'this': 1, 'is': 2, 'a': 3, 'story': 4, 'about': 5, 'cats': 6, 'our': 7, 'feline': 8, 'pets': 9, 'are': 10, 'furry': 11, 'animals': 12, 'surfing': 13, 'catching': 14, 'waves': 15, 'fun': 16, 'popular': 17, 'water': 18, 'sport': 19}\n"]}]},{"cell_type":"markdown","source":["Even though `test_2.txt` has 15 words, only 7 new words were added to the dictionary."],"metadata":{"id":"rxh0GaWpqVXZ"}},{"cell_type":"markdown","source":["## Feature Extraction\n","Now that we've encapsulated our \"entire language\" in a dictionary, let's perform *feature extraction* on each of our original documents:"],"metadata":{"id":"S_RS2hq2qX1d"}},{"cell_type":"code","source":["# Create an empty vector with space for each word in the vocabulary:\n","test_1 = ['test_1.txt']+[0]*len(vocab)\n","test_1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B1uhsMPoqQpF","executionInfo":{"status":"ok","timestamp":1641878098386,"user_tz":-330,"elapsed":36,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"805fc5d9-b1c9-45cf-abcf-a2acc2f39d71"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['test_1.txt', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# map the frequencies of each word in test_1.txt to our vector:\n","f1 = open(base_path + \"test_1.txt\", \"r\")\n","x = f1.read().lower().split()\n","f1.close()\n","    \n","for word in x:\n","    test_1[vocab[word]]+=1\n","    \n","test_1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqqCBY0jqsVl","executionInfo":{"status":"ok","timestamp":1641878098387,"user_tz":-330,"elapsed":34,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"fdfec06c-fcc4-4ec0-f4af-830274313f88"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['test_1.txt', 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["<font color=lightgreen>We can see that most of the words in test_1.txt appear only once, although \"cats\" appears twice.</font>"],"metadata":{"id":"8871ch1TrGxq"}},{"cell_type":"code","source":["# Do the same for the second document:\n","test_2 = ['test_2.txt']+[0]*len(vocab)\n","\n","f2 = open(base_path + 'test_2.txt', \"r\")\n","x = f2.read().lower().split()\n","f2.close()\n","    \n","for word in x:\n","    test_2[vocab[word]]+=1\n","\n","test_2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_bNbTy9Sq7GA","executionInfo":{"status":"ok","timestamp":1641878098388,"user_tz":-330,"elapsed":33,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"e0521432-81ec-4189-d7a1-a356749d2a5d"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['test_2.txt', 1, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Compare the two vectors:\n","print(f'{test_1}\\n{test_2}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MuZsSsDFraxR","executionInfo":{"status":"ok","timestamp":1641878098389,"user_tz":-330,"elapsed":31,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"894c6f2d-019d-421d-cf74-0efa0b073669"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["['test_1.txt', 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n","['test_2.txt', 1, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1]\n"]}]},{"cell_type":"markdown","source":["By comparing the vectors we see that some words are common to both, some appear only in `test_1.txt`, others only in `test_2.txt`. Extending this logic to tens of thousands of documents, we would see the vocabulary dictionary grow to hundreds of thousands of words. Vectors would contain mostly zero values, making them *sparse matrices*."],"metadata":{"id":"YMTTfvCIsG1Y"}},{"cell_type":"markdown","source":["## Bag of Words and Tf-idf\n","In the above examples, each vector can be considered a *bag of words*. By itself these may not be helpful until we consider *term frequencies*, or how often individual words appear in documents. A simple way to calculate term frequencies is to divide the number of occurrences of a word by the total number of words in the document. In this way, the number of times a word appears in large documents can be compared to that of smaller documents.\n","\n","However, it may be hard to differentiate documents based on term frequency if a word shows up in a majority of documents. To handle this we also consider *inverse document frequency*, which is the total number of documents divided by the number of documents that contain the word. In practice we convert this value to a logarithmic scale, as described [here](https://en.wikipedia.org/wiki/Tf%E2%80%93idf#Inverse_document_frequency).\n","\n","Together these terms become [**tf-idf**](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)."],"metadata":{"id":"e-hhD-xPsX2Y"}},{"cell_type":"markdown","source":["## Stop Words and Word Stems\n","Some words like \"the\" and \"and\" appear so frequently, and in so many documents, that we needn't bother counting them. Also, it may make sense to only record the root of a word, say `cat` in place of both `cat` and `cats`. This will shrink our vocab array and improve performance."],"metadata":{"id":"hh7Pl-eotFer"}},{"cell_type":"markdown","source":["## Tokenization and Tagging\n","When we created our vectors the first thing we did was split the incoming text on whitespace with `.split()`. This was a crude form of *tokenization* - that is, dividing a document into individual words. In this simple example we didn't worry about punctuation or different parts of speech. In the real world we rely on some fairly sophisticated *morphology* to parse text appropriately.\n","\n","Once the text is divided, we can go back and *tag* our tokens with information about parts of speech, grammatical dependencies, etc. This adds more dimensions to our data and enables a deeper understanding of the context of specific documents. For this reason, vectors become ***high dimensional sparse matrices***."],"metadata":{"id":"ZhNYcV0vtNsH"}},{"cell_type":"markdown","source":["# Feature Extraction from Text\n","In the **Scikit-learn Primer** lecture we applied a simple SVC classification model to the SMSSpamCollection dataset. We tried to predict the ham/spam label based on message length and punctuation counts. In this section we'll actually look at the text of each message and try to perform a classification based on content. We'll take advantage of some of scikit-learn's [feature extraction](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) tools.\n","\n","## Load a dataset"],"metadata":{"id":"fkXeems6tdBf"}},{"cell_type":"code","source":["# Perform imports and load the dataset:\n","import numpy as np\n","import pandas as pd\n","\n","df = pd.read_csv(base_path + 'smsspamcollection.tsv', sep='\\t')\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"zSbhudvatIVx","executionInfo":{"status":"ok","timestamp":1641878098390,"user_tz":-330,"elapsed":29,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"4dfa1b55-6703-49fc-8848-b5f44791807a"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-0f0c430c-938b-43f1-b042-9b2622fbfd00\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>message</th>\n","      <th>length</th>\n","      <th>punct</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","      <td>111</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","      <td>29</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","      <td>155</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","      <td>49</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","      <td>61</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f0c430c-938b-43f1-b042-9b2622fbfd00')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0f0c430c-938b-43f1-b042-9b2622fbfd00 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0f0c430c-938b-43f1-b042-9b2622fbfd00');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["  label                                            message  length  punct\n","0   ham  Go until jurong point, crazy.. Available only ...     111      9\n","1   ham                      Ok lar... Joking wif u oni...      29      6\n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n","3   ham  U dun say so early hor... U c already then say...      49      6\n","4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## Check for missing values:\n","Always a good practice."],"metadata":{"id":"ylS18IZguo_3"}},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1wR15mhQt4h-","executionInfo":{"status":"ok","timestamp":1641878098391,"user_tz":-330,"elapsed":29,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"79f103ca-f790-4688-ba8b-5b02604cb108"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["label      0\n","message    0\n","length     0\n","punct      0\n","dtype: int64"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["## Take a quick look at the *ham* and *spam* `label` column:"],"metadata":{"id":"UYll0sUBuubA"}},{"cell_type":"code","source":["value_count_df = df[\"label\"].value_counts()\n","\n","temp_df = pd.DataFrame()\n","temp_df[\"Label\"] = value_count_df.index\n","temp_df[\"Count\"] = value_count_df.values\n","temp_df[\"Percentage\"] = (value_count_df.values / value_count_df.values.sum()) * 100\n","temp_df[\"Percentage\"] = temp_df[\"Percentage\"].apply(lambda x: round(x, 3))\n","temp_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"lg66pefCusWb","executionInfo":{"status":"ok","timestamp":1641878098393,"user_tz":-330,"elapsed":28,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"c4f55c2e-704a-46d5-c833-43ef255f3f6c"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-f6463e33-3eb0-4261-a703-bab4769b36ab\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>Count</th>\n","      <th>Percentage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>4825</td>\n","      <td>86.594</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>spam</td>\n","      <td>747</td>\n","      <td>13.406</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6463e33-3eb0-4261-a703-bab4769b36ab')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f6463e33-3eb0-4261-a703-bab4769b36ab button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f6463e33-3eb0-4261-a703-bab4769b36ab');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["  Label  Count  Percentage\n","0   ham   4825      86.594\n","1  spam    747      13.406"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["<font color=lightgreen>4825 out of 5572 messages, or 86.594%, are ham. This means that any text classification model we create has to perform **better than 86.6%** to beat random chance.</font>"],"metadata":{"id":"duIhLJHBv4Qv"}},{"cell_type":"markdown","source":["## Split the data into train & test sets:"],"metadata":{"id":"SAZ7qDpowHE3"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X = df['message']  # this time we want to look at the text\n","y = df['label']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","X_train.shape, X_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PEEw_rUdvmj_","executionInfo":{"status":"ok","timestamp":1641878098394,"user_tz":-330,"elapsed":28,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"6cbb381c-2b47-4638-d121-904cb66f9399"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((4457,), (1115,))"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## Scikit-learn's CountVectorizer\n","Text preprocessing, tokenizing and the ability to filter out stopwords are all included in [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), which builds a dictionary of features and transforms documents to feature vectors."],"metadata":{"id":"ldI_ncNuwRTf"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","count_vect = CountVectorizer()\n","\n","X_train_counts = count_vect.fit_transform(X_train)\n","X_train_counts.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0fEsB9IbwNeP","executionInfo":{"status":"ok","timestamp":1641878099301,"user_tz":-330,"elapsed":932,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"56274d87-bf27-45a8-d10b-388cd251bab9"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4457, 7702)"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":[" - <font color=lightgreen>This shows that our training set is comprised of 4457 documents, and 7702 features.</font>\n","<br />\n"," - <font color=lightgreen>In simpler words our training data has 4457 records / rows. Each SMS is converted to a sparse vector of length 7702</font>"],"metadata":{"id":"6F-qkIZdwmze"}},{"cell_type":"markdown","source":["In our vectorized data each vector is of length 7702 which is decided buy the Vectorizer, but this length of the vectors can be controlled by the `max_features` parameter\n","\n","7702 values in a vector means we have 7701 unique values and the other remaining other are all counted in the last 1 value\n","\n","We can control this by giving the total number of words we want to encode i.e. if we pass `max_features = 1000` Vectorizer will keep 999 unique words and rest all will be considered in the last 1 value summing up to 1000.\n"],"metadata":{"id":"Yyt2hu-y3fMA"}},{"cell_type":"markdown","source":["## Transform Counts to Frequencies with Tf-idf\n","While counting words is helpful, longer documents will have higher average count values than shorter documents, even though they might talk about the same topics.\n","\n","To avoid this we can simply divide the number of occurrences of each word in a document by the total number of words in the document: these new features are called **tf** for Term Frequencies.\n","\n","<br />\n","$$\\text{Term Frequencies (tf) }= {\\text{Number of Occurrences of Each Word}\\over \\text{Total Number of Words in the Doucment}}$$\n","<br />\n","\n","Another refinement on top of **tf** is to downscale weights for words that occur in many documents in the corpus and are therefore less informative than those that occur only in a smaller portion of the corpus.\n","\n","This downscaling is called **tf–idf** for “Term Frequency times Inverse Document Frequency”.\n","\n","Both tf and tf–idf can be computed as follows using [TfidfTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html):"],"metadata":{"id":"hjjagzc4xSkG"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfTransformer\n","tfidf_transformer = TfidfTransformer()\n","\n","X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n","X_train_tfidf.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RPXjACUtwaRG","executionInfo":{"status":"ok","timestamp":1641878099302,"user_tz":-330,"elapsed":24,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"22ce7f3e-9797-4a56-c5ca-e39e9f5e6fa1"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4457, 7702)"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["Note: the `fit_transform()` method actually performs two operations: \n"," - It fits an estimator to the data and then \n"," - Transforms our count-matrix to a tf-idf representation."],"metadata":{"id":"E1BPXa96zeHq"}},{"cell_type":"markdown","source":["## Combine Steps with TfidVectorizer\n","In the future, we can combine the CountVectorizer and TfidTransformer steps into one using [TfidVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html):"],"metadata":{"id":"9Z9wvQAPzpEm"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","vectorizer = TfidfVectorizer()\n","\n","X_train_tfidf = vectorizer.fit_transform(X_train) # remember to use the original X_train set\n","X_train_tfidf.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VCGMa7qyzcEL","executionInfo":{"status":"ok","timestamp":1641878099303,"user_tz":-330,"elapsed":21,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"f3108aaf-f921-447d-b5a1-18d57f45e8d7"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4457, 7702)"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["## Train a Classifier\n","Here we'll introduce an SVM classifier that's similar to SVC, called [LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html). LinearSVC handles sparse input better, and scales well to large numbers of samples."],"metadata":{"id":"wR52_8FwzxPh"}},{"cell_type":"code","source":["from sklearn.svm import LinearSVC\n","\n","clf = LinearSVC()\n","\n","clf.fit(X_train_tfidf,y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P7NpseY3zuy2","executionInfo":{"status":"ok","timestamp":1641878099303,"user_tz":-330,"elapsed":18,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"ce92a346-b979-42f8-926b-436a6d193e84"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearSVC()"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["clf.get_params() # Parameters used by LinearSVC Classifier"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fLioS6J30Zc8","executionInfo":{"status":"ok","timestamp":1641878099304,"user_tz":-330,"elapsed":17,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"27abc03f-46f6-48ed-ccd2-5b1fe173acf4"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'C': 1.0,\n"," 'class_weight': None,\n"," 'dual': True,\n"," 'fit_intercept': True,\n"," 'intercept_scaling': 1,\n"," 'loss': 'squared_hinge',\n"," 'max_iter': 1000,\n"," 'multi_class': 'ovr',\n"," 'penalty': 'l2',\n"," 'random_state': None,\n"," 'tol': 0.0001,\n"," 'verbose': 0}"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["<font color=lightgreen>Earlier we named our SVC classifier **svc_model**. Here we're using the more generic name **clf** (for classifier).</font>"],"metadata":{"id":"Um0pHrmt0jnG"}},{"cell_type":"markdown","source":["## Build a Pipeline\n","Remember that only our training set has been vectorized into a full vocabulary. In order to perform an analysis on our test set we'll have to submit it to the same procedures. Fortunately scikit-learn offers a [**Pipeline**](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) class that behaves like a compound classifier."],"metadata":{"id":"DrzK2puc0nW2"}},{"cell_type":"code","source":["from sklearn import set_config\n","from sklearn.pipeline import Pipeline\n","# from sklearn.feature_extraction.text import TfidfVectorizer\n","# from sklearn.svm import LinearSVC\n","\n","set_config(print_changed_only=False)\n","\n","text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n","                     ('clf', LinearSVC()),\n","])\n","\n","# Feed the training data through the pipeline\n","text_clf.fit(X_train, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PkolNHoG0cd7","executionInfo":{"status":"ok","timestamp":1641878099305,"user_tz":-330,"elapsed":15,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"56dbba1c-79ef-49be-adaf-043e614c7ad1"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(memory=None,\n","         steps=[('tfidf',\n","                 TfidfVectorizer(analyzer='word', binary=False,\n","                                 decode_error='strict',\n","                                 dtype=<class 'numpy.float64'>,\n","                                 encoding='utf-8', input='content',\n","                                 lowercase=True, max_df=1.0, max_features=None,\n","                                 min_df=1, ngram_range=(1, 1), norm='l2',\n","                                 preprocessor=None, smooth_idf=True,\n","                                 stop_words=None, strip_accents=None,\n","                                 sublinear_tf=False,\n","                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n","                                 tokenizer=None, use_idf=True,\n","                                 vocabulary=None)),\n","                ('clf',\n","                 LinearSVC(C=1.0, class_weight=None, dual=True,\n","                           fit_intercept=True, intercept_scaling=1,\n","                           loss='squared_hinge', max_iter=1000,\n","                           multi_class='ovr', penalty='l2', random_state=None,\n","                           tol=0.0001, verbose=0))],\n","         verbose=False)"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## Test the classifier and display results"],"metadata":{"id":"O2KkuRU71JVW"}},{"cell_type":"code","source":["# Form a prediction set\n","predictions = text_clf.predict(X_test)"],"metadata":{"id":"zZX4jTxd0z4V","executionInfo":{"status":"ok","timestamp":1641878099305,"user_tz":-330,"elapsed":12,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn import metrics\n","\n","def classification_metrics(y_test, y_pred):\n","    # Calculating the Accuracy Score\n","    accuracy = metrics.accuracy_score(y_test, y_pred)\n","    print(\"Accuracy Score :\", accuracy, \"\\n\\n\")\n","\n","    # Classification Report\n","    print(\"Classification Report :\\n\")\n","    print(metrics.classification_report(y_test, y_pred), \"\\n\\n\")\n","\n","    # Confusion Matrix\n","    conf_matx = metrics.confusion_matrix(y_test, y_pred)\n","    conf_matx_df = pd.DataFrame(conf_matx, columns=[\"Predicted ham\", \"Predicted span\"], index=[\"True ham\", \"True span\"])\n","    ## Using Heatmap plot to show the Confusion Matrix\n","    plt.figure(dpi=80)\n","    sns.heatmap(conf_matx_df, annot=True, fmt='.0f')\n","    plt.title(\"Confuion Matrix - Heatmap\", fontdict={\"fontsize\": 12, \"fontweight\":\"bold\"})\n","    plt.show()"],"metadata":{"id":"jniSr73f1NOo","executionInfo":{"status":"ok","timestamp":1641878099306,"user_tz":-330,"elapsed":12,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["classification_metrics(y_test, predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":586},"id":"9zWei9JO19i0","executionInfo":{"status":"ok","timestamp":1641878100039,"user_tz":-330,"elapsed":745,"user":{"displayName":"Rohit Ingole","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYuiFQ_xdSGVkv64Gwwk_r53OUUl_sb3u7EypMiQ=s64","userId":"15140123141073107924"}},"outputId":"c7c37b22-9b97-4877-c005-8044c7d2b3e2"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy Score : 0.9919282511210762 \n","\n","\n","Classification Report :\n","\n","              precision    recall  f1-score   support\n","\n","         ham       0.99      1.00      1.00       966\n","        spam       0.99      0.95      0.97       149\n","\n","    accuracy                           0.99      1115\n","   macro avg       0.99      0.98      0.98      1115\n","weighted avg       0.99      0.99      0.99      1115\n"," \n","\n","\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 480x320 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Using the text of the messages, our model performed exceedingly well; it correctly predicted spam **98.97%** of the time!"],"metadata":{"id":"AfKdvlhR2N_e"}}]}